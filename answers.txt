# Fill in your name, student ID, and email address in this file.
# If you are working in a team, fill out the information for both team 
# members.

# SUBMIT THE LAB ONLY ONCE (from only one partner). This file will be
# automatically parsed in order to give both team members credit for the
# lab.

# You need to fill in the EXERCISE sections describing your solutions
# for Tasks 1, 2, and 3, as well as write the corresponding code.
# If you did one or more extra credit problems, indicate which one in the
# appropriate section below (remove the # sign first). If you have any other
# information you'd like us to know, please add it at the end of the file.

# Partner 1
Name: Chris Capistran
Student ID: 304-499-904
Email: capistranc@gmail.com

# Partner 2 (if you're working in a team)
Name: Amal Duriseti
Student ID: 904-331-855 
Email: aduriseti@gmail.com 

# EXERCISE 1: What method you used to make your peer download and upload
#    files in parallel?  (~1-3 sentences)

In the for loop for processing downloads, we forked a child process to run the download task and exit afterwards,
meanwhile the parent iterated through the rest of the loop creating a child to run each download task. We then
waited for all the download tasks to finish. Afterwards, we ran upload in parallel in the same manner.


# EXERCISE 2A: What conditions did you find and fix that would have
#    triggered a buffer overrun bug?  (~1-3 sentences each)
- start_download
	*We checked the filename to make sure it wasn't larger than the MAXFILESIZ, we also used strncpy to copy exactly
	the length of the file name into t->filename for extra security.
	
- task_upload
	Similarly, we checked the file name to make sure it wasn't too long.
	*parsed filename for any '/' as above.

		


# EXERCISE 2B: What other robustness problems did you fix?  (~1-3 sentences
#    each)
make run-bad: 
	-start_download
		*parsed filename for any '/' which would indicate the peer is attempint to access outside of its working directory
		*checked to see if the file was too large by creating global varialbe MAXFILESIZ, if t->totalwritten surpassed MAXFILESIZ
			we would drop the connection
			
	- task_upload
		*parsed filename for any '/' as above.
		
	-main file
		In while loop for task_upload, we checked that a peer wasn't attempting to upload the same file
		repeatedly by checking if peer file descriptor was the same as the previous tasks file descriptor.
		
make run-popular:
	- In start_download, tracker_task->buf stores all the peers before they can be added to the peerlist, the issue
	here was that the tracker_task->buf was being overflowed, a simple fix was to increase the TASKBUFFERSIZ to the max
	of 65535.
	
make run-slow:
	*Created globla variables SAMPLESIZE = 8, MINRATE = 128;
	-task_download
		In the while loop that reads data from the taskbuffer, we checked the average blocksize 
		in the first SAMPLESIZE blocks of data transfered by write_from_taskbuf. If the average blocksize
		was less than our MINRATE, we dropped the connection for being too slow

# Add any other information you'd like us to know below this line.
